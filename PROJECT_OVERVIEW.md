# Master Thesis ML Training - Projekt Ãœbersicht

Dieses Repository enthÃ¤lt zwei separate Training-Pipelines fÃ¼r Frame-Detection in Brexit-Debatten.

## ğŸ“ Projektstruktur

```
master-thesis-ml-training/
â”œâ”€â”€ data/                           # Gemeinsame Daten
â”‚   â”œâ”€â”€ training_data_export.csv
â”‚   â”œâ”€â”€ test_data_export.csv
â”‚   â””â”€â”€ debates_brexit_chunked.duckdb
â”‚
â”œâ”€â”€ classification/                 # Pipeline 1: Classification
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ training_config.yaml
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”‚   â””â”€â”€ inference.py
â”‚   â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ supervised_finetuning/         # Pipeline 2: Supervised Fine-Tuning
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ training_config.yaml
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ PROJECT_OVERVIEW.md            # Diese Datei
```

## ğŸ¯ Pipelines im Vergleich

### Pipeline 1: Classification

**Zweck**: Schnelle Multi-Class Classification fÃ¼r Frame-Detection

**Eigenschaften**:
- Multi-Class Classification Head
- Schnelles Training (3 Epochs)
- HÃ¶here Learning Rate (2e-4)
- Fokus auf Klassifikationsgenauigkeit

**Verwendung**:
```bash
cd classification/src
python train.py
```

[â†’ Mehr Details in classification/README.md](classification/README.md)

### Pipeline 2: Supervised Fine-Tuning

**Zweck**: Tiefes SprachverstÃ¤ndnis durch generatives Fine-Tuning

**Eigenschaften**:
- Supervised Fine-Tuning Ansatz
- LÃ¤ngeres Training (5 Epochs)
- Niedrigere Learning Rate (5e-5)
- Bessere Generalisierung

**Verwendung**:
```bash
cd supervised_finetuning/src
python train.py
```

[â†’ Mehr Details in supervised_finetuning/README.md](supervised_finetuning/README.md)

## ğŸ“Š Welche Pipeline wÃ¤hlen?

| Kriterium | Classification | Supervised Fine-Tuning |
|-----------|---------------|------------------------|
| **Training Zeit** | âš¡ Schneller (3 epochs) | ğŸ• LÃ¤nger (5 epochs) |
| **Genauigkeit** | âœ… Gut | âœ…âœ… Besser |
| **Generalisierung** | âœ… Akzeptabel | âœ…âœ… Sehr gut |
| **Ressourcen** | ğŸ’» Weniger | ğŸ’»ğŸ’» Mehr |
| **Use Case** | Schnelle Prototypen | Produktions-Models |

## ğŸš€ Quick Start

### 1. Repository klonen und Setup

```bash
git clone <repo-url>
cd master-thesis-ml-training
pip install -r requirements.txt
```

### 2. Daten vorbereiten

Die CSV-Dateien sollten bereits im `/data` Ordner vorhanden sein:
- `training_data_export.csv`
- `test_data_export.csv`

Falls nicht, generiere sie:
```bash
cd classification/scripts
python export_duckdb_to_csv.py
```

### 3. WÃ¤hle eine Pipeline und starte Training

**Classification:**
```bash
cd classification/src
python train.py
```

**Supervised Fine-Tuning:**
```bash
cd supervised_finetuning/src
python train.py
```

## ğŸ”§ Konfiguration

Beide Pipelines haben separate Konfigurationsdateien:
- `classification/config/training_config.yaml`
- `supervised_finetuning/config/training_config.yaml`

Wichtige Parameter:
- `batch_size`: Anpassen an verfÃ¼gbare GPU
- `learning_rate`: Experimentieren fÃ¼r beste Ergebnisse
- `num_epochs`: Mehr Epochs = bessere Performance (aber Overfitting-Risiko)
- `lora_r`: LoRA Rank (8, 16, 32)

## ğŸ“ˆ Metriken und Logging

Beide Pipelines nutzen Weights & Biases fÃ¼r Tracking:
- Classification: `gpt-oss-20b-brexit-debates`
- Supervised Fine-Tuning: `supervised-finetuning-brexit-debates`

Setup W&B:
```bash
wandb login
```

## ğŸ“ Frame-Kategorien

Beide Pipelines klassifizieren in 6 Kategorien:
1. **Conflict**: Konflikte und Auseinandersetzungen
2. **Moral Value**: Moralische und ethische Werte
3. **Economic**: Wirtschaftliche Aspekte
4. **Powerlessness**: Machtlosigkeit und Hilflosigkeit
5. **Human Impact**: Auswirkungen auf Menschen
6. **None**: Keine spezifische Frame

## ğŸ’¾ Datenformat

CSV-Format fÃ¼r beide Pipelines:
```csv
chunk_text,frame_name
"We know, of course, that...",Conflict
"I certainly would...",Moral Value
```

Spalten:
- `chunk_text`: Der zu klassifizierende Text
- `frame_name`: Die Frame-Kategorie

## ğŸ” Hardware-Anforderungen

**Minimum**:
- GPU: 24GB VRAM (z.B. RTX 3090, RTX 4090)
- RAM: 32GB
- Storage: 50GB

**Empfohlen**:
- GPU: RTX 5090 (48GB VRAM)
- RAM: 64GB
- Storage: 100GB+ (fÃ¼r Checkpoints)

## ğŸ› Troubleshooting

### OOM (Out of Memory)
```yaml
# In training_config.yaml reduzieren:
batch_size: 1
gradient_accumulation_steps: 32
max_length: 384
```

### Training zu langsam
- ErhÃ¶he `batch_size` wenn mÃ¶glich
- Reduziere `logging_steps` und `eval_steps`
- Nutze `fp16` statt `bf16` (falls GPU unterstÃ¼tzt)

### Schlechte Performance
- PrÃ¼fe Data Quality und Label Balance
- Experimentiere mit Learning Rate
- ErhÃ¶he `num_epochs`
- Versuche unterschiedliche `lora_r` Werte

## ğŸ“š Weitere Ressourcen

- [Transformers Dokumentation](https://huggingface.co/docs/transformers)
- [PEFT/LoRA Guide](https://huggingface.co/docs/peft)
- [Weights & Biases Docs](https://docs.wandb.ai)

## ğŸ¤ Contributing

Beide Pipelines kÃ¶nnen unabhÃ¤ngig voneinander entwickelt werden:
1. WÃ¤hle die relevante Pipeline
2. Erstelle einen Branch
3. Teste deine Ã„nderungen
4. Committe nur die betroffene Pipeline

## ğŸ“ Lizenz

[FÃ¼ge Lizenzinformationen hinzu]

## âœ‰ï¸ Kontakt

[FÃ¼ge Kontaktinformationen hinzu]
