# ğŸš€ RunPod Deployment Guide - GPT-OSS-20B Fine-Tuning

Komplette Anleitung fÃ¼r das Fine-Tuning von GPT-OSS-20B auf RunPod H100 GPU.

## ğŸ“‹ Voraussetzungen

- RunPod Account (https://runpod.io)
- DuckDB Datei: `debates_brexit_chunked.duckdb` mit training_data Tabelle
- Weights & Biases Account (optional, fÃ¼r Monitoring)

## ğŸ¯ Step-by-Step Anleitung

### Step 1: RunPod Pod Erstellen

1. **Einloggen** bei [RunPod.io](https://www.runpod.io/)
2. **WÃ¤hle GPU**: H100 SXM (80GB VRAM)
3. **Template auswÃ¤hlen**: 
   - `runpod/pytorch:2.1.0-py3.10-cuda12.1.1-devel`
   - Oder ein anderes PyTorch 2.x Template mit CUDA 12.x
4. **Storage**: Mindestens 100GB
5. **Pod starten**

### Step 2: Projekt Setup

#### Option A: Mit Git (empfohlen)

```bash
# SSH in Pod
ssh -p [PORT] root@[POD_IP]

# Repository klonen
cd /workspace
git clone [YOUR_REPO_URL]
cd ml_training
```

#### Option B: Manuelle Datei-Upload

1. Nutze den RunPod File Browser
2. Lade alle Dateien aus dem `ml_training/` Ordner hoch
3. Lade `debates_brexit_chunked.duckdb` in `data/` hoch

### Step 3: Environment Setup

```bash
cd /workspace/ml_training

# Python Dependencies installieren
pip install -r requirements.txt

# Setup-Script ausfÃ¼hrbar machen
chmod +x runpod_setup.sh

# Setup ausfÃ¼hren (prÃ¼ft System, GPU, etc.)
./runpod_setup.sh
```

### Step 4: Weights & Biases (Optional)

```bash
# API Key als Environment Variable setzen
export WANDB_API_KEY="your_wandb_api_key_here"

# Oder interaktiv einloggen
wandb login
```

Ohne W&B lÃ¤uft das Training trotzdem, nur ohne Online-Monitoring.

### Step 5: Training Starten

```bash
# Training starten
python3 src/train.py

# Das Training lÃ¤uft nun und zeigt Progress in der Konsole
```

**Erwartete Ausgabe:**
```
Lade Daten aus debates_brexit_chunked.duckdb...
Train Samples: XXXX
Test Samples: XXXX
Anzahl Labels: 6
Label Namen: ['label_1', 'label_2', ...]

Lade Model: openai-community/gpt-oss-20b
Konfiguriere LoRA...
trainable params: 83,886,080 || all params: 20,083,886,080 || trainable%: 0.4177

==================================================
Starte Training...
==================================================
```

### Step 6: Monitoring (in separatem Terminal)

**Terminal 1: Training lÃ¤uft**

**Terminal 2: GPU Monitoring**
```bash
# SSH in zweitem Terminal
ssh -p [PORT] root@[POD_IP]

# GPU Stats in Echtzeit
watch -n 1 nvidia-smi
```

**Terminal 3: TensorBoard (optional)**
```bash
ssh -p [PORT] root@[POD_IP]
cd /workspace/ml_training
tensorboard --logdir outputs --port 6006 --host 0.0.0.0
```

Dann Ã¶ffne: `http://[POD_IP]:6006`

## â±ï¸ Training Duration

Auf H100 SXM:
- **3 Epochs**: ~3-6 Stunden (abhÃ¤ngig von DatengrÃ¶ÃŸe)
- **Memory Usage**: ~45-55GB VRAM
- **Checkpoints**: Automatisch alle 500 Steps

## ğŸ“Š Training Outputs

Nach dem Training findest du:

```
ml_training/
â”œâ”€â”€ outputs/                          # Training Logs & TensorBoard
â”‚   â”œâ”€â”€ trainer_state.json
â”‚   â”œâ”€â”€ training_args.bin
â”‚   â””â”€â”€ [weitere Logs]
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ checkpoint-500/              # Zwischenspeicherungen
â”‚   â”œâ”€â”€ checkpoint-1000/
â”‚   â””â”€â”€ final_model/                 # Finales trainiertes Model
â”‚       â”œâ”€â”€ config.json
â”‚       â”œâ”€â”€ adapter_model.bin        # LoRA Weights
â”‚       â”œâ”€â”€ adapter_config.json
â”‚       â””â”€â”€ [weitere Dateien]
```

## ğŸ¯ Nach dem Training

### Evaluation durchfÃ¼hren

```bash
python3 src/evaluate.py
```

Dies erstellt `evaluation_results/` mit:
- `metrics.json` - Detaillierte Metriken
- `confusion_matrices.png` - Visualisierungen
- `label_distribution.png` - Label-Verteilung

### Test Inference

```bash
python3 src/inference.py
```

Oder im Python Script:
```python
from src.inference import DebateClassifier

classifier = DebateClassifier(
    checkpoint_path="checkpoints/final_model",
    threshold=0.5
)

text = "Brexit hat die Beziehung zwischen UK und EU verÃ¤ndert."
result = classifier.predict(text)
print(result['predicted_labels'])
print(result['label_scores'])
```

## ğŸ’¾ Checkpoints Herunterladen

### Option 1: RunPod File Browser
1. Navigiere zu `checkpoints/final_model/`
2. Download alle Dateien

### Option 2: SCP
```bash
# Auf deinem lokalen Computer:
scp -P [PORT] -r root@[POD_IP]:/workspace/ml_training/checkpoints/final_model ./local_checkpoints/
```

### Option 3: Cloud Storage
```bash
# In RunPod Terminal:
pip install awscli  # oder gsutil fÃ¼r GCP

# Upload zu S3
aws s3 cp checkpoints/final_model/ s3://your-bucket/models/ --recursive

# Oder zu Google Cloud
gsutil -m cp -r checkpoints/final_model/ gs://your-bucket/models/
```

## ğŸ”§ Konfiguration Anpassen

Bearbeite `config/training_config.yaml`:

```yaml
training:
  num_epochs: 3              # Mehr Epochs fÃ¼r bessere Performance
  batch_size: 4              # Reduzieren bei OOM
  learning_rate: 2e-4        # Anpassen fÃ¼r bessere Konvergenz
  
  # Bei Memory-Problemen:
  batch_size: 2
  gradient_accumulation_steps: 16  # BehÃ¤lt effektive Batch Size bei
```

## ğŸ› Troubleshooting

### Out of Memory (OOM)

**Symptom:** `CUDA out of memory` Error

**LÃ¶sung:**
```yaml
# In training_config.yaml:
training:
  batch_size: 2              # Von 4 auf 2
  gradient_accumulation_steps: 16  # Von 8 auf 16
```

### DuckDB Connection Error

**Symptom:** `duckdb.IOException: Cannot open file`

**LÃ¶sung:**
```bash
# PrÃ¼fe Dateipfad
ls -lh data/debates_brexit_chunked.duckdb

# PrÃ¼fe Permissions
chmod 644 data/debates_brexit_chunked.duckdb
```

### Model Loading Failed

**Symptom:** `OSError: Model openai-community/gpt-oss-20b not found`

**LÃ¶sung:**
```bash
# Manuell Model herunterladen
from transformers import AutoModel
model = AutoModel.from_pretrained("openai-community/gpt-oss-20b", cache_dir="./models")
```

### Training sehr langsam

**Check:**
```bash
# GPU Auslastung prÃ¼fen
nvidia-smi

# Falls GPU Utilization < 70%:
# - ErhÃ¶he batch_size
# - PrÃ¼fe ob BF16 aktiviert ist (sollte true sein)
# - Stelle sicher dass CUDA richtig konfiguriert ist
python3 -c "import torch; print(torch.cuda.is_available())"
```

## ğŸ“ˆ Performance Erwartungen

### Mit Standard-Config (H100):

| Metric | Wert |
|--------|------|
| Training Time | 3-6h fÃ¼r 3 Epochs |
| VRAM Usage | 45-55GB |
| GPU Utilization | 80-95% |
| Samples/Sec | ~15-25 |
| Trainable Params | 84M (0.4%) |

### Erwartete Metriken (nach Training):

| Metric | Erwarteter Bereich |
|--------|-------------------|
| F1 Macro | 0.65 - 0.85 |
| F1 Micro | 0.70 - 0.90 |
| Accuracy | 0.75 - 0.95 |

## ğŸ’° Kosten-Kalkulation

RunPod H100 SXM:
- **Preis**: ~$4.00/Stunde (variiert)
- **Training (6h)**: ~$24
- **Mit Idle Time**: +20% Buffer = ~$30

**Tipp**: Stoppe den Pod sofort nach Download der Checkpoints!

## ğŸ” Best Practices

1. **RegelmÃ¤ÃŸige Checkpoints**: Alle 500 Steps (bereits konfiguriert)
2. **Monitoring**: Nutze W&B oder TensorBoard
3. **Backup**: Lade Checkpoints wÃ¤hrend Training hoch (nicht warten bis Ende)
4. **Pod Management**: Stoppe Pod wenn nicht in Verwendung
5. **Screen/Tmux**: Nutze fÃ¼r lange Training Sessions
   ```bash
   tmux new -s training
   python3 src/train.py
   # Ctrl+B, dann D zum Detachen
   # tmux attach -t training zum Wiederverbinden
   ```

## ğŸ“ Support

Bei Problemen:
1. Check Logs in `outputs/`
2. PrÃ¼fe `nvidia-smi` fÃ¼r GPU Status
3. Teste mit kleinerem Subset der Daten
4. ÃœberprÃ¼fe DuckDB Daten-Schema

## ğŸ“ NÃ¤chste Schritte

Nach erfolgreichem Training:
1. âœ… Evaluation durchfÃ¼hren
2. âœ… Checkpoints downloaden
3. âœ… Model in Production deployen
4. âœ… Inference auf neuen Daten testen
5. âœ… Hyperparameter-Tuning fÃ¼r bessere Performance

---

**Happy Training! ğŸš€**
